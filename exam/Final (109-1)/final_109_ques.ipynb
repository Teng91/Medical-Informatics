{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;color:#888888;\"><h2> IMP 5001 - Introduction to Medical Informatics </h2></div>\n",
    "<div style=\"text-align:center;\"><h1> Final Exam (109-1) </h1></div>\n",
    "\n",
    "* Exam date: 2021/01/14 9:10-12:10\n",
    "* There are 8 questions, 100 points in total.\n",
    "* Open everything including the Internet. Feel free to import any package you need.\n",
    "* \"Cheating\" is basically coordinating with others. So don't do that.\n",
    "* When you find necessary to raise an exception, please include a meaningful error message to indicate what the source of the error is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exam, you are given a data set in <b>data/diabetes.csv</b>, where the data attributes are described as follows: (all numeric-valued)\n",
    "\n",
    "* <b>Pregnancies</b> - Number of times pregnant\n",
    "* <b>Glucose</b> - Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "* <b>BloodPressure</b> - Diastolic blood pressure (mm Hg)\n",
    "* <b>SkinThickness</b> - Triceps skin fold thickness (mm\n",
    "* <b>Insulin</b> - 2-Hour serum insulin (mu U/ml)\n",
    "* <b>BMI</b> - Body mass index (weight in kg/(height in m)^2)\n",
    "* <b>DiabetesPedigreeFunction</b> - Diabetes pedigree function\n",
    "* <b>Age</b> - Age (years)\n",
    "* <b>TestResult</b> - Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>TestResult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6    148.0           72.0           35.0      NaN  33.6   \n",
       "1            1     85.0           66.0           29.0      NaN  26.6   \n",
       "2            8    183.0           64.0            NaN      NaN  23.3   \n",
       "3            1     89.0           66.0           23.0     94.0  28.1   \n",
       "4            0    137.0           40.0           35.0    168.0  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age TestResult  \n",
       "0                     0.627   50   Positive  \n",
       "1                     0.351   31   Negative  \n",
       "2                     0.672   32   Positive  \n",
       "3                     0.167   21   Negative  \n",
       "4                     2.288   33   Positive  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/diabetes.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Question 1:</span> Separate Features and Class Labels (12 pts)\n",
    "\n",
    "The data frame loaded from <b>data/diabetes.csv</b> contains both the features as well as the class label (i.e., the <b>TestResult</b> column).  Write a function called `separateInputOutput` that\n",
    "* Separates the features and the class labels out from the data frame.\n",
    "* The class labels are label-encoded as numerical values (0 and 1).\n",
    "* Extract the names of the features.\n",
    "* Extract the class names.\n",
    "\n",
    "<span style=\"color:green\"> <b>Examples:</b></span>\n",
    "```python\n",
    "X_orig, y, feature_names,class_names = separateInputOutput(df)\n",
    "feature_names\n",
    "class_names\n",
    "X_orig[0:4]\n",
    "y[0:4]\n",
    "class_names[y][0:4]\n",
    "```\n",
    "Should result in\n",
    "```python\n",
    "array(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',\n",
    "       'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age'], dtype=object)\n",
    "array(['Negative', 'Positive'], dtype=object)\n",
    "array([[6.00e+00, 1.48e+02, 7.20e+01, 3.50e+01,      nan, 3.36e+01,\n",
    "        6.27e-01, 5.00e+01],\n",
    "       [1.00e+00, 8.50e+01, 6.60e+01, 2.90e+01,      nan, 2.66e+01,\n",
    "        3.51e-01, 3.10e+01],\n",
    "       [8.00e+00, 1.83e+02, 6.40e+01,      nan,      nan, 2.33e+01,\n",
    "        6.72e-01, 3.20e+01],\n",
    "       [1.00e+00, 8.90e+01, 6.60e+01, 2.30e+01, 9.40e+01, 2.81e+01,\n",
    "        1.67e-01, 2.10e+01]])\n",
    "array([1, 0, 1, 0])\n",
    "array(['Positive', 'Negative', 'Positive', 'Negative'], dtype=object)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1: Please write your code here\n",
    "def separateInputOutput(df):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>TestResult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction, Age, TestResult]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = df.iloc[0:0,:]\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ec85595f8cfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseparateInputOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "X_orig, y, feature_names, class_names = separateInputOutput(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Empty DataFrame\n",
       "Columns: [Pregnancies, Glucose...\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['Negative', 'Positive'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[6.00e+00, 1.48e+02, 7.20e+01, 3.50e+01,      nan, 3.36e+01,\n",
       "        6.27e-01, 5.00e+01],\n",
       "       [1.00e+00, 8.50e+01, 6.60e+01, 2.90e+01,      nan, 2.66e+01,\n",
       "        3.51e-01, 3.10e+01],\n",
       "       [8.00e+00, 1.83e+02, 6.40e+01,      nan,      nan, 2.33e+01,\n",
       "        6.72e-01, 3.20e+01],\n",
       "       [1.00e+00, 8.90e+01, 6.60e+01, 2.30e+01, 9.40e+01, 2.81e+01,\n",
       "        1.67e-01, 2.10e+01]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Negative', 'Positive', 'Negative'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For testing Q1. Feel free to alter as this cell will not be graded.\n",
    "feature_names\n",
    "class_names\n",
    "X_orig[0:4]\n",
    "y[0:4]\n",
    "class_names[y][0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = np.load('npz/Q1.npz',allow_pickle = True)\n",
    "X_orig = arch['X_orig']\n",
    "y = arch['y']\n",
    "feature_names = arch['feature_names']\n",
    "class_names = arch['class_names']\n",
    "arch.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Question 2:</span> Plot Feature Histograms (12 pts)\n",
    "\n",
    "It is important to understand the features, and the first step towards that is to visualize their distribution.  Check out the API reference [matplotlib.pyplot.hist](https://matplotlib.org/3.3.1/api/_as_gen/matplotlib.pyplot.hist.html) on the Internet, and write a function called `plotFeatureHistograms` that plots the histogram for each each feature, where each histogram has 20 bins.\n",
    "\n",
    "<span style=\"color:green\"> <b>Examples:</b></span>\n",
    "```python\n",
    "plotFeatureHistograms(df,feature_names)\n",
    "```\n",
    "Should result in <img src='figures/Q2.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2: Please write your code here\n",
    "def plotFeatureHistograms(df,feature_names):\n",
    "    plt.figure(figsize=(9,9))\n",
    "    plt.subplots_adjust(hspace=0.35)\n",
    "    for idx,feature in enumerate(feature_names):\n",
    "        if idx > 8:\n",
    "            break\n",
    "        plt.subplot(3, 3, idx+1,title=feature)\n",
    "        # Please write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing Q2. Feel free to alter as this cell will not be graded.\n",
    "plotFeatureHistograms(df,feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Question 3:</span> Impute Missing Data (12 pts)\n",
    "\n",
    "Some features in <b>X_orig</b> are missing and we need to impute missing data. Write a function called `imputeMissingData` that impute the missing data with the median imputing stretagy.\n",
    "\n",
    "\n",
    "<span style=\"color:green\"> <b>Examples:</b></span>\n",
    "```python\n",
    "X_toy = [[     6,     8,np.nan,     9],\n",
    "         [     8,     3,     1,np.nan],\n",
    "         [np.nan,np.nan,     9,     7],\n",
    "         [     9,     0,     6,np.nan]]\n",
    "imputeMissingData(X_toy)\n",
    "```\n",
    "Should result in\n",
    "```python\n",
    "array([[6., 8., 6., 9.],\n",
    "       [8., 3., 1., 8.],\n",
    "       [8., 3., 9., 7.],\n",
    "       [9., 0., 6., 8.]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3: Please write your code here\n",
    "def imputeMissingData(X_orig):\n",
    "    import scipy.sparse as sp\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    X = X_orig\n",
    "    imp = SimpleImputer(missing_values = np.nan, strategy = 'median')\n",
    "    imp.fit(X)\n",
    "    print(imp.transform(X))#.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing Q3. Feel free to alter as this cell will not be graded.\n",
    "X_toy = [[     6,     8,np.nan,     9],\n",
    "         [     8,     3,     1,np.nan],\n",
    "         [np.nan,np.nan,     9,     7],\n",
    "         [     9,     0,     6,np.nan]]\n",
    "imputeMissingData(X_toy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_im = imputeMissingData(X_toy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = np.load('npz/Q3.npz',allow_pickle = True)\n",
    "X_im = arch['X_im']\n",
    "arch.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_im, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Question 4:</span> Standardize Features (12 pts)\n",
    "\n",
    "Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less have similar dynamic range. Check out the API reference [sklearn.preprocessing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) on the Internet, and write a function called `standardizeFeatures` that normalizes each feature so they have the same dynamic range.  More precisely, for any given feature, the feature value $x$ is transformed to $z = (x-l)/(u-l)$, where $l$ is the minimum feature value, and $u$ is the maximum feature value.\n",
    "\n",
    "<span style=\"color:green\"> <b>Examples:</b></span>\n",
    "```python\n",
    "X_toy = [[ 6, 8,-4, 9],\n",
    "         [ 8, 3, 1,-7],\n",
    "         [-7,-8, 9, 9]]\n",
    "standardizeFeatures(X_toy,[[ 9, 0, 6,-7]])\n",
    "```\n",
    "Should result in\n",
    "```python\n",
    "(array([[0.86666667, 1.        , 0.        , 1.        ],\n",
    "        [1.        , 0.6875    , 0.38461538, 0.        ],\n",
    "        [0.        , 0.        , 1.        , 1.        ]]),\n",
    " array([[1.06666667, 0.5       , 0.76923077, 0.        ]]))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4: Please write your code here\n",
    "def standardizeFeatures(X_train,X_test):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std, X_test_std = standardizeFeatures(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing Q4. Feel free to alter as this cell will not be graded.\n",
    "X_toy = [[ 6, 8,-4, 9],\n",
    "         [ 8, 3, 1,-7],\n",
    "         [-7,-8, 9, 9]]\n",
    "standardizeFeatures(X_toy,[[ 9, 0, 6,-7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = np.load('npz/Q4.npz',allow_pickle = True)\n",
    "X_train_std = arch['X_train_std']\n",
    "X_test_std = arch['X_test_std']\n",
    "arch.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Question 5:</span> Transform Features (12 pts)\n",
    "\n",
    "Polynomial features are a common way to represent the nonlinear interactions between features.  For instance, if an input sample is two dimensional and of the form $(a,b)$, the degree-2 polynomial features are $(1, a, b, a^2, ab, b^2)$. Check out the API reference [sklearn.preprocessing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) on the Internet, and write a function called `PolynomialFeatures` that generates new feature matrices consisting of all polynomial combinations of the features with degree at most 2, for both the training and testing data.\n",
    "\n",
    "<span style=\"color:green\"> <b>Examples:</b></span>\n",
    "```python\n",
    "transformFeatures(np.array([[2,3],[5,7]]), np.array([[-2,5]]))\n",
    "```\n",
    "Should result in\n",
    "```python\n",
    "(array([[ 1.,  2.,  3.,  4.,  6.,  9.],\n",
    "        [ 1.,  5.,  7., 25., 35., 49.]]),\n",
    " array([[  1.,  -2.,   5.,   4., -10.,  25.]]))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Question 5: Please write your code here\n",
    "def transformFeatures(X_train_std, X_test_std):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing Q5. Feel free to alter as this cell will not be graded.\n",
    "transformFeatures(np.array([[2,3],[5,7]]), np.array([[-2,5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_poly, X_test_poly = transformFeatures(X_train_std,X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = np.load('npz/Q5.npz',allow_pickle = True)\n",
    "X_train_poly = arch['X_train_poly']\n",
    "X_test_poly = arch['X_test_poly']\n",
    "arch.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Question 6:</span> Linear Discriminant Analysis and Visualize (14 pts)\n",
    "\n",
    "You might be wondering if the extracted features are good enough to separate the various classes. A common trick is to apply Linear discriminant analysis (LDA) so that each data point is represented by just a scalar, to which one may plot the histogram of those scalar representation of data point for each class. Write a function called `LDAVisualize` that performs LDA and reduce feature dimension to 1, and then plot the histogram of the (dimension-reduced) data for each class.\n",
    "\n",
    "<span style=\"color:green\"> <b>Examples:</b></span>\n",
    "```python\n",
    "X_toy = np.array([[0,0],[0,1],[0,2],[0,3],[0,4],[0,5],[1,1],[1,4],[2,0],[2,1],[2,2],[2,3],[2,4],[2,5]])\n",
    "y_toy = np.array([    0,    0,    0,    1,    1,    1,    0,    1,    0,    0,    0,    1,    1,    1])\n",
    "LDAVisualize(X_toy,y_toy,class_names)\n",
    "```\n",
    "Should result in\n",
    "```python\n",
    "array([[-3.06186218],\n",
    "       [-1.83711731],\n",
    "       [-0.61237244],\n",
    "       [ 0.61237244],\n",
    "       [ 1.83711731],\n",
    "       [ 3.06186218],\n",
    "       [-1.83711731],\n",
    "       [ 1.83711731],\n",
    "       [-3.06186218],\n",
    "       [-1.83711731],\n",
    "       [-0.61237244],\n",
    "       [ 0.61237244],\n",
    "       [ 1.83711731],\n",
    "       [ 3.06186218]])\n",
    "```\n",
    "<img src=\"figures/Q6.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 6: Please write your code here\n",
    "def LDAVisualize(X,y,class_names):\n",
    "    # Write your code here\n",
    "    plt.figure(figsize=(8,4))\n",
    "    for i in range(len(class_names)):\n",
    "        plt.subplot(1, 2, i+1,title=class_names[i])\n",
    "        # Write your code here\n",
    "    return X_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing Q6. Feel free to alter as this cell will not be graded.\n",
    "X_toy = np.array([[0,0],[0,1],[0,2],[0,3],[0,4],[0,5],[1,1],[1,4],[2,0],[2,1],[2,2],[2,3],[2,4],[2,5]])\n",
    "y_toy = np.array([    0,    0,    0,    1,    1,    1,    0,    1,    0,    0,    0,    1,    1,    1])\n",
    "LDAVisualize(X_toy,y_toy,class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lda = LDAVisualize(X_train_std,y_train,class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = np.load('npz/Q6.npz',allow_pickle = True)\n",
    "X_train_lda = arch['X_train_lda']\n",
    "arch.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Question 7:</span> K Nearest Neighbor With Additional Settings (12 pts)\n",
    "\n",
    "K-nearest neighbors (KNN) is a simple and effective tool for classification problems.  Check out the API reference [sklearn.neighbors.KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) on the Internet, and write a function called `myKNN` that returns a KNN model which\n",
    "\n",
    "* Classifies a query point based on its 3 nearest neighbors.\n",
    "* The neighbors do not vote equally, instead their votes are weighted inversely proportional to their distance.  In other words, closer neighbors of a query point will have a greater influence than neighbors which are further away.\n",
    "* The distance between two $m$-dimensional points ${\\bf u} = (u_1,...,u_m)$ and ${\\bf v} = (v_1,...,v_m)$ is computed as\n",
    "$$d({\\bf u},{\\bf v}) = \\sum_{i=1}^m |u_i-v_i|$$\n",
    "\n",
    "<span style=\"color:green\"> <b>Examples:</b></span>\n",
    "```python\n",
    "X_toy = [[0],[1],[2],[3],[4],[5],[6],[7],[8]]\n",
    "y_toy = [0,0,0,0,0,1,1,1,0]\n",
    "knn_toy = myKNN()\n",
    "knn_toy.fit(X_toy,y_toy)\n",
    "z_toy = knn_toy.predict_proba([[3.6],[5.2]])\n",
    "```\n",
    "Then the value for <b>z_toy</b> should be\n",
    "```python\n",
    "array([[0.85365854, 0.14634146],\n",
    "       [0.11764706, 0.88235294]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 7: Please write your code here\n",
    "def myKNN():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing Q7. Feel free to alter as this cell will not be graded.\n",
    "X_toy = [[0],[1],[2],[3],[4],[5],[6],[7],[8]]\n",
    "y_toy = [0,0,0,0,0,1,1,1,0]\n",
    "knn_toy = myKNN()\n",
    "knn_toy.fit(X_toy,y_toy)\n",
    "z_toy = knn_toy.predict_proba([[3.6],[5.2]])\n",
    "z_toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = myKNN()\n",
    "knn.fit(X_train_std, y_train)\n",
    "Z_test = knn.predict_proba(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = np.load('npz/Q7.npz',allow_pickle = True)\n",
    "Z_test = arch['Z_test']\n",
    "arch.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Question 8:</span> K Nearest Neighbor With Weighted Classes (14 pts)\n",
    "\n",
    "A common stretagy towards imbalanced dataset is to assign class-dependent weights to each data point. In that case, the data points of the majority class will be assigned less weights then that of the minority class.\n",
    "\n",
    "For instace, consider a KNN model constructed and trained by\n",
    "```python\n",
    "X_toy = [[0],[1],[2],[3],[4],[5],[6],[7],[8],[9]]\n",
    "y_toy = [0,0,0,0,0,1,1,1,0,1]\n",
    "knn_toy = KNeighborsClassifier(n_neighbors=4)\n",
    "knn_toy.fit(X_toy,y_toy)\n",
    "```\n",
    "For query point $3.6$, the KNN model will find its four nearest neighbors as follows:\n",
    "\n",
    "| <!-- --> | <!-- --> |\n",
    "| --- | --- |\n",
    "| <b>Neighbor point</b> | <b>Neighbor label</b> |\n",
    "| 4.0  | 0    |\n",
    "| 3.0  | 0    |\n",
    "| 5.0  | 1    |\n",
    "| 2.0  | 0    |\n",
    "\n",
    "Among the four neighbors, 3 (=75%) belongs to class 0, and 1 (=25%) belongs to class 1.  Hence if one computes\n",
    "```python\n",
    "knn_toy.predict_proba([[3.6]])\n",
    "```\n",
    "It will return\n",
    "```python\n",
    "array([[0.75, 0.25]])\n",
    "```\n",
    "\n",
    "Suppose now for each data point we assign weights inversely proportional to the portion of class it belongs to. That is, as there are 6 (=60%) data points belonging to class 0, and 4 (=40%) data points belonging to class 1, the weights of the four nearest neighbors of query point $3.6$ are given by\n",
    "\n",
    "| <!-- --> | <!-- --> | <!-- --> |\n",
    "| --- | --- | --- |\n",
    "| <b>Neighbor point</b> | <b>Neighbor label</b> | <b>Neighbor Weight</b>|\n",
    "| 4.0  | 0 | $1/0.6 \\approx 1.67$ |\n",
    "| 3.0  | 0 | $1/0.6 \\approx 1.67$ |\n",
    "| 5.0  | 1 | $1/0.4 = 2.5$ |\n",
    "| 2.0  | 0 | $1/0.6 \\approx 1.67$ |\n",
    "\n",
    "Under such circumstances, we say the query point has a \"portion\" of $\\frac{3/0.6}{3/0.6 + 1/0.4} \\approx 0.67$ belonging to class 0, and a \"portion\" of $\\frac{1/0.4}{3/0.6 + 1/0.4} \\approx 0.33$ belonging to class 1.\n",
    "\n",
    "Write a function called `classWeightAdjustedProba` that, when given a KNN model, the class weights, and query points, will return the portions of each query point beloning to each class.\n",
    "\n",
    "<span style=\"color:green\"> <b>Examples:</b></span>\n",
    "```python\n",
    "X_toy = [[0],[1],[2],[3],[4],[5],[6],[7],[8],[9]]\n",
    "y_toy = [0,0,0,0,0,1,1,1,0,1]\n",
    "knn_toy = KNeighborsClassifier(n_neighbors=4)\n",
    "knn_toy.fit(X_toy,y_toy)\n",
    "knn_toy.predict_proba([[3.6],[5.2]])\n",
    "classWeightAdjustedProba(knn_toy,len(y_toy)/np.bincount(y_toy),[[3.6],[5.2]])\n",
    "```\n",
    "Should result in\n",
    "```python\n",
    "KNeighborsClassifier(n_neighbors=4)\n",
    "array([[0.75, 0.25],\n",
    "       [0.25, 0.75]])\n",
    "array([[0.66666667, 0.33333333],\n",
    "       [0.18181818, 0.81818182]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 8: Please write your code here\n",
    "def classWeightAdjustedProba(model,class_weight,X_test):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing Q8. Feel free to alter as this cell will not be graded.\n",
    "X_toy = [[0],[1],[2],[3],[4],[5],[6],[7],[8],[9]]\n",
    "y_toy = [0,0,0,0,0,1,1,1,0,1]\n",
    "knn_toy = KNeighborsClassifier(n_neighbors=4)\n",
    "knn_toy.fit(X_toy,y_toy)\n",
    "knn_toy.predict_proba([[3.6],[5.2]])\n",
    "classWeightAdjustedProba(knn_toy,len(y_toy)/np.bincount(y_toy),[[3.6],[5.2]])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
